{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "runner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keran-w/speech-lexical-segmentation/blob/main/runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title upload\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# dataset_dir = next(iter(uploaded))\n",
        "# !unzip {dataset_dir}\n",
        "# dataset_dir = dataset_dir[:-4]\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# dataset_dir = 'Lost_in_the_Jungle' # 95/97 (57)\n",
        "# dataset_dir = 'B7-05_The_Willow_Pattern_Plot' # 99/99\n",
        "# dataset_dir = 'B7-08_The_Joke_Machine' # 87/93\n",
        "# dataset_dir = 'Australian_Adventure' # 98/98\n",
        "dataset_dir = 'a_day_in_london'\n",
        "# dataset_dir = 'the_rainbow_machine'\n",
        "# !rm -r {dataset_dir}\n",
        "!unzip drive/MyDrive/Datasets/Audio_Segmentation/{dataset_dir}.zip -d ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqIkZ2YLlrEZ",
        "outputId": "7c19009a-4f3e-4e23-ae1d-c122ea02b021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-255a0a2a-046c-48ef-89bf-0a676aeebca7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-255a0a2a-046c-48ef-89bf-0a676aeebca7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title initialize\n",
        "! pip install pydub\n",
        "# ! pip install speechbrain\n",
        "! pip install transformers\n",
        "! pip install similarities\n",
        "\n",
        "import re\n",
        "import os\n",
        "import IPython\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "from similarities import Similarity\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from time import time\n",
        "import json\n",
        "\n",
        "from tqdm import tqdm\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "import speechbrain as sb\n",
        "from speechbrain.dataio.dataio import read_audio\n",
        "import numpy as np\n",
        "from IPython.display import Audio \n",
        "from more_itertools import consecutive_groups\n",
        "\n",
        "# from speechbrain.pretrained import SepformerSeparation\n",
        "\n",
        "import logging\n",
        "logging.disable(logging.CRITICAL)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "torch.random.manual_seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# separator = SepformerSeparation.from_hparams(source=\"speechbrain/sepformer-wsj02mix\", savedir='pretrained_models/sepformer-wsj02mix')\n",
        "processor = Wav2Vec2Processor.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-english')\n",
        "model = Wav2Vec2ForCTC.from_pretrained('jonatasgrosman/wav2vec2-large-xlsr-53-english').to(device)\n",
        "\n",
        "def if_any_alpha(str):\n",
        "    for c in str:\n",
        "        if c.isalpha(): return False\n",
        "    return True\n",
        "\n",
        "idx_list = []\n",
        "for p in os.listdir(f'{dataset_dir}/audio/'):\n",
        "    segs = p.split('.')\n",
        "    if segs[1] == 'mp3': \n",
        "        try: idx_list.append(int(segs[0]))\n",
        "        except: pass\n",
        "idx_list = sorted(idx_list)"
      ],
      "metadata": {
        "id": "TOv8-WKJiVTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title run\n",
        "def process(audio_path, json_path):\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    waveform = torchaudio.functional.resample(waveform[1].to(device), sample_rate, 16000)\n",
        "\n",
        "    input_values = processor(waveform, return_tensors='pt', sampling_rate=16000, padding='longest').input_values.to(device)\n",
        "    logits = model(input_values).logits.squeeze()\n",
        "\n",
        "    fragments = json.load(open(json_path, 'r'))['fragments']\n",
        "    texts = [d['lines'][0].lower() for d in fragments]\n",
        "    decodings = processor.decode(logits.argmax(1), output_char_offsets=True).char_offsets\n",
        "    flag = word_start_offset = prev_word_end_offset = 0\n",
        "    word = ''\n",
        "    res = []\n",
        "\n",
        "    for decoding in decodings:\n",
        "        char, start_offset, end_offset = decoding.values()\n",
        "        if start_offset > end_offset: start_offset, end_offset = end_offset, start_offset\n",
        "\n",
        "        if char not in (' ', '-'):\n",
        "            word += char\n",
        "            if word_start_offset == 0: word_start_offset = start_offset\n",
        "            prev_word_end_offset = end_offset\n",
        "        else:\n",
        "            res.append([word, word_start_offset, prev_word_end_offset, prev_word_end_offset - word_start_offset])\n",
        "            word = ''\n",
        "            word_start_offset = 0\n",
        "\n",
        "    res = np.array(res)\n",
        "    filter_texts = list(filter(None, [re.sub('[^a-z]+', '', text) for text in texts]))\n",
        "    filter_res = [re.sub('[^a-z]+', '', text) for text in res[:, 0]]\n",
        "\n",
        "    if len(filter_texts) != len(filter_res):\n",
        "\n",
        "        matched_list = []\n",
        "        min_j = 0\n",
        "        for i, word_res in enumerate(filter_res):\n",
        "            for j, word_text in enumerate(filter_texts):\n",
        "                if j < min_j:\n",
        "                    continue\n",
        "                if word_res == word_text:\n",
        "                    min_j = j\n",
        "                    matched_list.append([i, j])\n",
        "                    break\n",
        "\n",
        "        matched_list = np.array(matched_list)\n",
        "        res_lst, texts_lst = np.setdiff1d(np.arange(len(filter_res)), matched_list[:, 0]), np.setdiff1d(np.arange(len(filter_texts)), matched_list[:, 1])\n",
        "\n",
        "        if len(filter_texts) < len(filter_res):\n",
        "\n",
        "            similarity = Similarity(model_name_or_path='bert-base-uncased', similarity_type='cosine', embedding_type='sbert')\n",
        "            corpus = [filter_texts[ti] for ti in texts_lst]\n",
        "            similarity.add_corpus(corpus)\n",
        "\n",
        "            sentences = res[res_lst, 0]\n",
        "            sentences_list = [(*sentences[:si], sentences[si] + sentences[si+1], *sentences[si+2:]) for si in range(len(sentences) - 1)]\n",
        "\n",
        "            max_sim_sum, sen = 0, None\n",
        "            for sentences in sentences_list:\n",
        "                sim = similarity.most_similar(queries=list(sentences), topn=1)\n",
        "                sim_sum = sum([list(sim_val.values())[0] for sim_val in sim.values()])\n",
        "                if sim_sum > max_sim_sum:\n",
        "                    max_sim_sum, sen = sim_sum, sentences\n",
        "\n",
        "            for ri, _ in enumerate(res[:-1]):\n",
        "                if res[ri, 0] == '': continue\n",
        "                if res[ri, 0] + res[ri + 1, 0] in sen:\n",
        "                    res[ri] = res[ri, 0] + res[ri + 1, 0], res[ri, 1], res[ri + 1, 2], ''\n",
        "                    res[ri + 1] = '', '', '', ''\n",
        "\n",
        "            res = res[res[:, 0] != '']\n",
        "\n",
        "        elif len(filter_texts) > len(filter_res):\n",
        "            \n",
        "            add_rows = []\n",
        "            for rl, tl in zip([list(group) for group in consecutive_groups(res_lst)], [list(group) for group in consecutive_groups(texts_lst)]):\n",
        "                if len(rl) == len(tl) or len(rl) > 1: continue\n",
        "                rl = rl[0]\n",
        "                start, end = int(res[rl][1]), int(res[rl][2])\n",
        "                l = logits[start:end+1]\n",
        "                l_idx = l[:, 4].argmax().item()\n",
        "                add_text = processor.decode(l[l_idx:].argmax(1))\n",
        "                if add_text != '':\n",
        "                    add_rows.append((rl, [add_text, start + l_idx + 1, end, end - (start + l_idx + 1)]))\n",
        "\n",
        "            count = 1\n",
        "            for ari, ar in add_rows:\n",
        "                res = np.insert(res, ari + count, ar, 0)\n",
        "                count += 1\n",
        "        \n",
        "        filter_res = [re.sub('[^a-z]+', '', text) for text in res[:, 0]]\n",
        "    return decodings, res, filter_texts, filter_res\n",
        "\n",
        "f = open(f'{dataset_dir}.txt', 'w')\n",
        "correct_info = []\n",
        "wrong_info = []\n",
        "wrong_idx_list = []\n",
        "for idx in tqdm(idx_list):\n",
        "    audio_path = f'{dataset_dir}/audio/{idx}.mp3'\n",
        "    json_path = f'{dataset_dir}/json/G-({idx}).json'\n",
        "    try: open(json_path, 'r')\n",
        "    except: \n",
        "        f.write(f'File Not Found: {json_path}\\n')\n",
        "        continue\n",
        "\n",
        "    decodings, res, filter_texts, filter_res = process(audio_path, json_path)\n",
        "    duration = AudioSegment.from_file(audio_path).duration_seconds\n",
        "    scale = decodings[-1]['end_offset'] / duration\n",
        "\n",
        "    markers = json.load(open(json_path, 'r'))\n",
        "    r = [int(res_row[1]) for res_row in res] + [decodings[-1]['end_offset']]\n",
        "    s = [(r[ri], r[ri+1]) for ri in range(len(r) - 1)]\n",
        "        \n",
        "    for (b, e), marker in zip(s, markers['fragments']):\n",
        "        marker['begin'] = f'{int(b) / scale:.3f}'\n",
        "        marker['end'] = f'{int(e) / scale:.3f}'\n",
        "\n",
        "    f.write(f'\\nG-{idx}.json\\n')\n",
        "    f.write(json.dumps(markers, indent = 4))\n",
        "\n",
        "    if len(filter_texts) != len(filter_res):\n",
        "        wrong_idx_list.append(idx)\n",
        "        wrong_info.append(f\"{idx:2d}.mp3 - original({len(filter_texts)}): {' ' if len(filter_texts) < 10 else ''}     {' '.join(filter_texts)}\")\n",
        "        wrong_info.append(f\"{idx:2d}.mp3 - prediction({len(filter_res)}): {' ' if len(filter_res) < 10 else ''}   {' '.join(filter_res)}\")\n",
        "\n",
        "    else:\n",
        "        correct_info.append(f\"{idx:2d}.mp3 - original:          {' '.join(filter_texts)}\")\n",
        "        correct_info.append(f\"{idx:2d}.mp3 - prediction:        {' '.join(filter_res)}\")\n",
        "\n",
        "f.write('\\ncorrect_info\\n')\n",
        "f.write('\\n'.join(correct_info))\n",
        "f.write('\\nwrong_info\\n')\n",
        "f.write('\\n'.join(wrong_info))\n",
        "f.close()\n",
        "from google.colab import files\n",
        "files.download(f'{dataset_dir}.txt')"
      ],
      "metadata": {
        "id": "LQn3pCjZjsxh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}